
En esta sección se detallan los experimentos realizados para abordar las cuestiones propuestas en la sección \ref{introduccion}. En primer lugar, se introducen los detalles del diseño de la experimentación: la selección del modelo de segmentación, dataset elegido, procesos de entrenamiento y validación, etc. Después, se detalla el pipeline implementado para realizar la anotación semiautomática de las máscaras de ocupación, oclusión y área conducible. Finalmente, se aborda la metodología seguida para evaluar tanto la generación de las máscaras semánticas en \aclink{BEV}, como las detecciones 3D a partir de imágenes monoculares para la evaluación final del pipeline de anotación semiautomática.

Este proyecto puede dividirse en 3 bloques principales: experimentación con la segmentación semántica en BEV, diseño e implementación de un sistema de anotación semiautomático de máscaras de área conducible y un tercer bloque de experimentación para evaluar el rendimiento del sistema implementado.

\subsection{Diseño del experimento de segmentación: BEV2Seg\_2}
\label{bev2seg_2}

Para abordar la hipótesis de "Un modelo de segmentación semántica entrenado con imágenes BEV segmenta mejor los elementos planares", se ha diseñado el proceso descrito en la Figura \ref{fig:beg2seg_2_flow}. En él se siguen dos rutas principales: la segmentación de imágenes RGB normales y su reproyección con \aclink{IPM} a BEV y realizar \aclink{IPM} de la imagen original para luego realizar la segmentación semántica con el modelo.

\begin{figure}[h!]
    \centering
    \includegraphics[width=\linewidth]{./images/metodology/bev2seg_2_flow.png}
    \caption{bev2seg\_2 diagram flow}
    \label{fig:beg2seg_2_flow}
\end{figure}

Considerando este diagrama de flujo surgen tres cuestiones principales: (1) qué modelo de segmentación utilizar; (2) con qué base de datos entrenar los modelos y (3) cómo realizar la comparación entre los modelos entrenados.


\subsubsection{Segformer}
Como se ha analizado en el estado del arte \ref{sota}, existen numerosas técnicas para abordar el task de la segmentación semántica y varias de estas técnicas ya se han aplicado al contexto de la segmentación semántica en BEV en el contexto de los \aclink{ADS}. En este punto nos encontramos ante una gran variedad de opciones entre las que elegir. Una de ellas es si optar por modelos CNN o ViT. Tras varias pruebas de distintos modelos \cite{dummy} \cite{dummy} \cite{dummy} se ha tomado la decisión de utilizar segformer \cite{segformer}, un ViT para segmentación semántica que destaca por su eficiencia y rendimiento que consigue resultados del estado del arte.

Explicar cómo funciona segformer por encima.

La estrategia de entrenamiento consiste en utilizar encoders ya entrenados de Segformer y finetunearlos para el task específico: segmentación semántica de escenas vehiculares. Concretamente, encontramos 6 tamaños de encoders MIT (Mix Transformer encoder): mit-b0, mit-b1, mit-b2, mit-b3, mit-b4, y mit-b5. Estos encoders están preentrenados en el dataset ImageNet-1K.

La implementación de segformer que se ha seleccionado es la proporcionada por huggingface \cite{huggingface}, ya que cuenta con una API sencilla para entrenar y evaluar los modelos, permite el entrenamiento paralelizado en varias GPU y la utilización de varias CPU y también permite ajustar los hyperparámetros y definir funciones específicas para el entrenamiento.

\hl{hablar sobre cómo es el preprocesado de las imágenes para segformer. También el tema de <<reduce labels>> e <<ignore index>> y cual es la configuración de los modelos pre entrenados. También hay que ver si los pesos preentrenados se congelan o se siguen ajustando. En el caso de segmentar con imágenes BEV, los pesos del encoder deberían reajustarse; en el caso de las imágenes normales creo que da más igual}.

\subsubsection{Dataset de entrenamiento}
Existen numerosos datasets 

City

\subsubsection{Data augmentations}
\subsubsection{Validación y comparación}
Se ha utilizado mIou per class para la evaluación durante el entrenamiento y la comparación de los dos aproaches.


\subsection{Anotación semiautomática del área conducible}
\label{aplicacion}

\subsubsection{Depth estimation}
\subsubsection{Scene PCD}
\subsubsection{Instance scene PCD}
\subsubsection{Instance BEV mask}

\subsection{Metodología de evaluación}
\label{evaluacion}

\subsubsection{Evaluación de detecciones 3d}
\subsubsection{¿Evaluación de máscaras BEV?}
\hl{se podrían generar las máscaras BEV a partir del groundtruth}


