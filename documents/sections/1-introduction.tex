% ================================================
% =                INTRODUCTION                  =
% ================================================ 
The development of \aclink{ADS} has been a hot topic in the automotive industry for the last years. These systems rely on a combination of sensors and algorithms to perform driving tasks, either partially or fully replacing the human driver. A fundamental component of any ADS is its perception system,  which is responsible for detecting obstacles and generating a reliable representation of the surrounding environment.

One key element within the perception system is the generation of a local \aclink{BEV} map. A local \aclink{BEV} map provides a top-down, 2D representation of the vehicle's immediate surroundings, typically centered on the vehicle's position. Unlike raw sensor data, which is captured from the perspective of individual cameras or LiDAR units, the \aclink{BEV} map projects this information onto an unified ground-level plane, creating a structured grid in metric space. Each cell in the grid represents a precise location in the real world, enabling the system to interpret spatial relationships between road elements, obstacles, and free space with high accuracy.

Generating a segmented \aclink{BEV} map improves the perception system by providing rich semantic information and precise obstacle localization within a metric space. Semantic \aclink{BEV} representations are useful for a variety of tasks, including scene understanding, map reconstruction, behavior prediction of surrounding agents, and trajectory planning.

To obtain \aclink{BEV} semantic segmentation from cameras, traditional methods first generate semantic masks in image space and then transform them into \aclink{BEV} space using \aclink{IPM}. Despite its simplicity, it requires accurate camera parameters and assumes a perfectly flat ground surface, which limits its effectiveness. Moreover, while planar or low-height objects such as road curbs, lane markings, and the drivable area retain a meaningful metric representation in \aclink{BEV} space, objects with height appear distorted after the transformation.

With the objective of addressing the afore mentioned limitations, recent methods leverage data-driven techniques for \aclink{BEV} representation \cite{view_parsing_network} \cite{lift_splat_shoot} \cite{m2bev}. However, to the best of our knowledge, no prior work has investigated the impact of training a standard semantic segmentation model directly on \aclink{BEV} images, with the aim of evaluating whether this approach improves performance on planar elements.

The main objective of this master's thesis is to investigate the hypothesis: \textit{Does training a semantic segmentation model directly on \aclink{BEV} images outperforms the traditional image-space segmentation followed by \aclink{IPM} reprojection?} Additionally, this work explores a technical application of \aclink{BEV} semantic segmentation for annotating vehicular scenes with occupancy, occlusion, and drivable area masks, contributing to the field of monocular 3D object detection given 2D semantic masks.





% ================================================ 
% The development of \aclink{ADS} has been a hot topic in the automotive industry for the last years. One of the fundamental aspects of an \aclink{ADS} is the perception system, as it is responsible for performing the obstacle detection and to provide a good environment representation for other systems, among others. This perception system can be divided into two main tasks: 3D object detection and local \aclink{BEV} map generation. 
% 3D object detection is usually based on pointclouds obtained from \aclink{LiDAR} sensors, but as this sensors are costly a lot of research has been made in the field of camera 3D object detection. This approach has been gaining a lot of popularity carried by the improvements of the computer vision techniques with deep learning.
% \aclink{BEV} segmentation aims to create a semantic representation of a vehicle's surroundings. This is a key component of an \aclink{ADS} perception system as \aclink{BEV} segmentation provides rich semantic information, precise localization, and absolute scales. This makes it useful for various tasks, including map reconstruction, prediction of agent intentions, and vehicle path planning.
% To obtain \aclink{BEV} semantic segmentation from cameras, traditional methods first generate semantic masks in image space and then transform them into \aclink{BEV} space using \aclink{IPM}. Despite its simplicity, it requires accurate camera parameters and assumes a perfectly flat ground surface, which limits its effectiveness. Moreover, while planar or low-height objects such as road curbs, lane markings, and the drivable area retain a meaningful metric representation in \aclink{BEV} space, objects with height appear distorted after the transformation.
% With the objective of addressing the afore mentioned limitations, recent methods leverage data-driven techniques for \aclink{BEV} representation \cite{view_parsing_network} \cite{lift_splat_shoot} \cite{m2bev}. However, to the best of our knowledge, no previous work has explored training a standard semantic segmentation model directly on \aclink{BEV} images to measure the difference between the inference of planar elements.
% This master's thesis seeks to answer the question: \textit{Does a model directly trained on semantic BEV images outperforms a typical segmentation model for plannar elements?}. Additionally, this work explores a technical application of \aclink{BEV} semantic segmentation for annotating vehicular scenes with occupancy, occlusion, and drivable area masks, contributing to the field of monocular 3D object detection given 2D semantic masks.


