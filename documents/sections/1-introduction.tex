% ================================================
% =                INTRODUCTION                  =
% ================================================ 

The development of \aclink{ADS} have been a hot topic in the automotive industry for the last years. One of the fundamental aspects of an \aclink{ADS} is its perception system, as it is responsible for performing the obstacle detection and to provide a good environment representation for other systems. This perception system can be divided in two main tasks: 3D object detection and local \aclink{BEV} map generation. 

3D object detection is usually based on pointclouds obtained from \aclink{LiDAR} sensors, but as this sensors are costly a lot of research has been made in the field of camera 3D object detection. This approach has been gaining a lot of popularity carried by the improvemnts of the computer vision techniques with deeplearning. \hl{references for 3d camera object detection. Also add some context about how bev3d detection is performed.}

\aclink{BEV} segmentation aims to create a semantic representation of a vehicle's surroundings. This is a key component of an \aclink{ADS} perception system as \aclink{BEV} segmentation provides rich semantic information, precise localization, and absolute scales. This makes it useful for various tasks, including map reconstruction, prediction of agent intentions, and vehicle path planning.

To obtain \aclink{BEV} semantic segmentation from cameras, traditional methods first generate semantic masks in image space and then transform them into \aclink{BEV} space using \aclink{IPM}. Although simple, it requires accurate camera parameters and assumes a perfectly flat ground surface which limits its effectiveness. Moreover, while planar or low-height objects—such as road curbs, lane markings, and the drivable area—retain a meaningful metric representation in \aclink{BEV} space, objects with height appear distorted after the transformation.

With the objective of addressing this limitations, recent methods leverage data-driven techniques for \aclink{BEV} representation. VPN \cite{view_parsing_network} introduces a two-layer MLP module for multi-camera feature fusion, followed by a decoder for semantic segmentation in indoor scenes. LSS \cite{lift_splat_shoot} proposes a unified framework that lifts 2D images into a 3D space by learning an implicit depth distribution and shows that their method is suitable for end-to-end motion plannig. M\^{} 2BEV \cite{m2bev} transforms 2D image features into 3D voxels along projection rays and obtains an efficient \aclink{BEV} representation which supports multiple end tasks such as semantic segmentation or object 3D detection.


However, to the best of our knowledge, no previous work has explored training a standard semantic segmentation model directly on \aclink{BEV} images to measure the difference between the inference of planar elements.

This maste's thesis seeks to answer the question: \textit{Does a model directly trained with semantic BEV images outperforms a typical segmentation model for plannar elements?}. Additionally, this work explores a technical application of \aclink{BEV} semantic segmentation for pre-annotating vehicular scenes with occupancy, occlusion, and drivable area masks, contributing to the field of monocular 3D object detection.